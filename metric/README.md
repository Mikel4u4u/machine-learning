# Метрические алгоритмы классификации

## Алгоритм k ближайших соседей – **kNN**

### Выбор данных

Выборка состоит из 150 экземпляров ирисов трех видов, имеет четыре характеристики: длина и ширина чашелистика (`Sepal.Length` и `Sepal.Width`), длина и ширина лепестка (`Petal.Length` и `Petal.Width`)

![Iris](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png)

### Евклидово расстояние

![](https://latex.codecogs.com/svg.latex?%5Cfn_phv%20%5Crho%28u%2C%20v%29%20%3D%20%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20%7B%7Cu_i%20-%20v_i%7C%7D%5E%7B2%7D%29%5E%7B1/2%7D)

```R
euclideanDistance <- function(u, v) {
 sqrt(sum((u - v)^2))
}
```
### Функция kNN

**Пример:**
```
kNN(train = trainIris, test = testIris, cl = trainIris$Species, k = 3)
```

**Аргументы:**

`train` - обучающая выборка

`test` - контрольная выборка

`cl` - ответы (идентификаторы классов) обучающей выборки

`k` - колличество ближайших соседей, которое используется

Возвращает предсказания на тестовой выборке

### Критерий скользящего контроля LOO для kNN

Оптимальное в смысле точности предсказаний значение  `k`  может быть найдено с использованием перекрестной проверки. Для этого по фиксированному значению  `k`  строится модель  `k` -ближайших соседей и оценивается CV-ошибка классификации. Эти действия повторяются для различных  `k`  и значение, соответствующее наименьшей ошибке распознавания, принимается как оптимальное.

![LOO kNN](graphics/LOOknn.png)

### Карта	классификации kNN

![kNN](graphics/kNN.png)
---

## Алгоритм	k взвешенных	ближайших	соседей	– **kwNN**
 
### Критерий	скользящего	контроля	LOO для kwNN

![LOO kNN](graphics/LOOkwnn.png)

### Карта	классификации	kwNN

![kNN](graphics/kwNN.png)
---

## Сравнение	качества	алгоритмов	kNN и	kwNN.

## Пример,	показывающий	преимущество	метода kwNN над kNN.
	


